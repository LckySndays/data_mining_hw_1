{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 房智宏\n",
    "\n",
    "Student ID: 106062404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the dataset provided in this [link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The sentiment dataset contains a `sentence` and `score` label. Read what the dataset is about on the link provided before you start exploring it. \n",
    "\n",
    "\n",
    "- Then, you are asked to apply each of the data exploration and data operation techniques learned in the [first lab session](https://goo.gl/Sg4FS1) on the new dataset. You don't need to explain all the procedures as we did in the notebook, but you are expected to provide some **minimal comments** explaining your code. You are also expected to use the same libraries used in the first lab session. You are allowed to use and modify the `helper` functions we provided in the first lab session or create your own. Also, be aware that the helper functions may need modification as you are dealing with a completely different dataset. This part is worth 80% of your grade!\n",
    "\n",
    "\n",
    "- After you have completed the operations, you should attempt the **bonus exercises** provided in the [notebook](https://goo.gl/Sg4FS1) we used for the first lab session. There are six (6) additional exercises; attempt them all, as it is part of your grade (10%). \n",
    "\n",
    "\n",
    "- You are also expected to tidy up your notebook and attempt new data operations that you have learned so far in the Data Mining course. Surprise us! This segment is worth 10% of your grade.\n",
    "\n",
    "\n",
    "- After completing all the above tasks, you are free to remove this header block and submit your assignment following the guide provided in the `README.md` file of the assignment's [repository](https://github.com/omarsar/data_mining_hw_1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "\n",
    "# Plotly API Credential\n",
    "py.sign_in('DataMiningNTHU', 'ch8eNTh6fUr5JwagjUcd')\n",
    "\n",
    "# Disable Warning to tidy up\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the files (Converted directly into Pandas Dataframe)\n",
    "df1 = pd.read_csv('dataset/amazon_cells_labelled.txt', '\\t', names = [\"Sentence\", \"Score\"])\n",
    "df2 = pd.read_csv('dataset/imdb_labelled.txt', '\\t', names = [\"Sentence\", \"Score\"])\n",
    "df3 = pd.read_csv('dataset/yelp_labelled.txt', '\\t', names = [\"Sentence\", \"Score\"])\n",
    "\n",
    "# Checking Total Record (Each dataset should have exact 1000 record)\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C Engine failed to parse some of the data from imdb_labelled.txt (Bad Data)\n",
    "# Fallback to Python Parser (Quick Fix)\n",
    "df2 = pd.read_csv('dataset/imdb_labelled.txt', ' \\t', names = [\"Sentence\", \"Score\"], engine='python', encoding=None)\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Verify if data parsed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data was read correctly\n",
    "df1[:5]\n",
    "#df2[:5]\n",
    "#df3[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Spot Bad Formatted Data\n",
    "#### We may need to fix this format later on if it cause us some problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>\" I love it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence  Score\n",
       "322  \" I love it.       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence with prefix ([\" ])\n",
    "df2[322:323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>) a happy, wonderful, feel good ending!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sentence  Score\n",
       "732  ) a happy, wonderful, feel good ending!       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence with prefix ([) ])\n",
    "df2[732:733]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 0:** Experiment with other querying techniques using pandas dataframes. Refer to the their documentation for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "5  I have to jiggle the plug to get it to line up...      0\n",
       "6  If you have several dozen or several hundred c...      0\n",
       "8                Needless to say, I wasted my money.      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query DataFrame#1 with Score value equal to 0 (query with expression)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html\n",
    "df1.query('Score == 0')[0:5]\n",
    "# Equivalence with df[df.Score==0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Preparation\n",
    "#### Since we already convert the data directly into pandas dataframe earlier, the data is already well prepared for us. No need to take another significant action to prepare it. We can just try to get familiar with the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Score\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1\n",
       "5     Now I am getting angry and I want my damn pho.      0\n",
       "6              Honeslty it didn't taste THAT fresh.)      0\n",
       "7  The potatoes were like rubber and you could te...      0\n",
       "8                          The fries were great too.      1\n",
       "9                                     A great touch.      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 data of DataFrame3\n",
    "df3[0:10][[\"Sentence\", \"Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>:) Anyway, the plot flowed smoothly and the ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>The opening sequence of this gem is a classic,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Fans of the genre will be in heaven.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Lange had become a great actress.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>It looked like a wonderful story.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>I never walked out of a movie faster.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Score\n",
       "989  :) Anyway, the plot flowed smoothly and the ma...      1\n",
       "990  The opening sequence of this gem is a classic,...      1\n",
       "991              Fans of the genre will be in heaven.       1\n",
       "992                 Lange had become a great actress.       1\n",
       "993                 It looked like a wonderful story.       1\n",
       "994             I never walked out of a movie faster.       0\n",
       "995  I just got bored watching Jessice Lange take h...      0\n",
       "996  Unfortunately, any virtue in this film's produ...      0\n",
       "997                    In a word, it is embarrassing.       0\n",
       "998                                Exceptionally bad!       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last 10 data of DataFrame2\n",
    "df2[-11:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And the sound quality is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I went on Motorola's website and followed all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>This is a simple little phone to use, but the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>It has a great camera thats 2MP, and the pics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Not loud enough and doesn't turn on like it sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Essentially you can forget Microsoft's tech su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Mic Doesn't work.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>I wear it everyday and it holds up very well.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>For a product that costs as much as this one d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  Score\n",
       "0   So there is no way for me to plug it in here i...      0\n",
       "10                    And the sound quality is great.      1\n",
       "20  I went on Motorola's website and followed all ...      0\n",
       "30  This is a simple little phone to use, but the ...      0\n",
       "40  It has a great camera thats 2MP, and the pics ...      1\n",
       "50  Not loud enough and doesn't turn on like it sh...      0\n",
       "60  Essentially you can forget Microsoft's tech su...      0\n",
       "70                                  Mic Doesn't work.      0\n",
       "80      I wear it everyday and it holds up very well.      1\n",
       "90  For a product that costs as much as this one d...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query every 10th record of DataFrame1 \n",
    "df1.iloc[::10, :][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Dimensionality Reduction & Discretization and Binarization Demonstration, we add new feature here called datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Score datasource\n",
       "0  So there is no way for me to plug it in here i...      0     amazon\n",
       "1                        Good case, Excellent value.      1     amazon\n",
       "2                             Great for the jawbone.      1     amazon\n",
       "3  Tied to charger for conversations lasting more...      0     amazon\n",
       "4                                  The mic is great.      1     amazon"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in df1:\n",
    "    df1['datasource'] = \"amazon\"\n",
    "for row in df2:\n",
    "    df2['datasource'] = \"imdb\"\n",
    "for row in df3:\n",
    "    df3['datasource'] = \"yelp\"\n",
    "    \n",
    "df1[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Missing Value\n",
    "\n",
    "#### For this step, I divide the task into 2 main task as following:\n",
    "1. We first create new testing data frame to check whether our function is working properly as expected. \n",
    "2. After we are making sure that the function is working properly, we then apply it into the original data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Testing function against Testing DataFrame\n",
    "#### Notice that \"empty\" and \"Null\" are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create New Testing Data Frame\n",
    "MissingDF = pd.DataFrame([['EmptyValue', ''], ['NullValue', np.nan]], columns=['Sentence', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentence  Score\n",
       "0    False  False\n",
       "1    False   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Null Value\n",
    "pd.isnull(MissingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EmptyValue</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence Score\n",
       "0  EmptyValue      "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Empty Value\n",
    "MissingDF.query('Score == \"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Code for how to calculate the missing values for every record instead of every column. Hint `axis` parameter. Check the documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also print out which line/row number where the missing value is located. [BUGGED]\n",
    "def check_missing_values2(table):\n",
    "    \"\"\" functions that check and verifies if there are missing values in dataframe \"\"\"\n",
    "    row = 0\n",
    "    column = 0\n",
    "    counter = 0\n",
    "    for element in table:\n",
    "        column+=1\n",
    "        \n",
    "        if element == True:\n",
    "            if column == 1:\n",
    "                print(\"Line \" + str(row) + \" Sentence=>\" + str(element))\n",
    "            else:\n",
    "                print(\"Line \" + str(row) + \" Score=>\" + str(element))\n",
    "            counter+=1\n",
    "        \n",
    "        if column==2:\n",
    "            # This Row Value below will back to 0 in the next loop (Not Sure why)\n",
    "            # Already check it in Java, and there is no problem\n",
    "            row+=1\n",
    "            column=0\n",
    "            \n",
    "    return (\"Missing Value Counter :\" + str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0 Score=>True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Missing Value Counter :0\n",
       "1    Missing Value Counter :1\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(MissingDF).apply(lambda x: check_missing_values2(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the correct function should return \"Line 1 Score=>True\" instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Applying the function against Original Dataframe\n",
    "#### To simplify the whole process, we merge the 3 original dataframe into 1 before processing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Original Data Frame\n",
    "MergeDF = pd.concat([df1, df2, df3])\n",
    "len(MergeDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original function from news_data_mining.ipynb\n",
    "def check_missing_values(row):\n",
    "    \"\"\" functions that check and verifies if there are missing values in dataframe \"\"\"\n",
    "    counter = 0\n",
    "    for element in row:\n",
    "        if element == True:\n",
    "            counter+=1\n",
    "    return (\"The amoung of missing records is: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence      (The amoung of missing records is: , 0)\n",
       "Score         (The amoung of missing records is: , 0)\n",
       "datasource    (The amoung of missing records is: , 0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Null Value\n",
    "pd.isnull(MergeDF).apply(lambda x: check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentence, Score, datasource]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Empty Value of Score\n",
    "MergeDF.query('Score == \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentence, Score, datasource]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Empty Value of Sentence\n",
    "MergeDF.query('Sentence == \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At this moment, No Missing Value detected\n",
    "# In case if there is missing value, we may need to process it further\n",
    "# Or for simplicity, we may remove it directly from the DataFrame\n",
    "MergeDF.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove Duplicate\n",
    "#### After merging all the dataset, we may find out that some of the record are duplicated, so we may need to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the sum of the duplicated record\n",
    "sum(MergeDF.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sum of record before removing duplicate\n",
    "len(MergeDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing just duplicate but preserving a copy of it\n",
    "MergeDF.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2983"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sum of record after removing duplicate\n",
    "len(MergeDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Sampling & Visualizing\n",
    "#### If our dataframe contains huge amount of records, it is better to sample it first before we process it, especially if we are using low-end computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Sampling with just 25% of the data randomly\n",
    "SampleDF = MergeDF.sample(frac=0.25, replace=False)\n",
    "len (SampleDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: We can also do a side by side comparison of the distribution between the two datasets, but maybe you can try that as an excerise. Look at the Plotly documents for tons of examples and ways to visualizing groups bar charts.\n",
    "\n",
    "I must also make mention that there are other libraries for visualizing, but we are going to focus on that in the later sections. For now, we just show you what are the ways to sample and to verify the distributions of your samplings. I can't resits it, but actually, there is an easier to generate the chart we generated above using a library called matplotlib. With matplotlib, things are faster and compatability-wise it may just be the best visualization library for visualizing content extracted from dataframes. Let's quickly take a loot at the magic of matplotlib below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGx5JREFUeJzt3X20JVV55/HvjxcRBRRCh2l5SaOBzAAGlA5hRV2DmgiK\nCThRaWIEE0YwEkeNyQSSrIhJOoN5UWMUHIwIGBXa0QyogEHURI0IDSLQINIKDLQtdHwBNAaheeaP\n2jccLrfvPdXd557T3O9nrVq3alftOk/17Xue2ruqdqWqkCSpj63GHYAkactj8pAk9WbykCT1ZvKQ\nJPVm8pAk9WbykCT1ZvKQJPVm8pAk9WbykCT1ts24AxiVXXfdtZYsWTLuMCRpi3L11Vf/a1Utmmu7\nx2zyWLJkCStXrhx3GJK0RUly+zDb2W0lSerN5CFJ6s3kIUnqzeQhSeptZMkjyeOTXJnkq0lWJXlL\nK98lyWVJbmk/dx6oc2qS1UluTnL4QPnBSa5v696ZJKOKW5I0t1G2PO4HnldVBwIHAUckORQ4Bbi8\nqvYBLm/LJNkPWAbsDxwBnJFk67avM4FXA/u06YgRxi1JmsPIkkd1ftAWt21TAUcB57byc4Gj2/xR\nwPlVdX9V3QqsBg5JshjYqaquqO61h+cN1JEkjcFIr3kk2TrJtcDdwGVV9WVgt6pa2zb5NrBbm98d\nuGOg+p2tbPc2P71ckjQmI00eVbW+qg4C9qBrRRwwbX3RtUY2iyQnJlmZZOW6des2124lSdPMyxPm\nVfX9JJ+lu1ZxV5LFVbW2dUnd3TZbA+w5UG2PVramzU8vn+lzzgLOAli6dOlmS0rSQrDklE+OO4TN\n5rbTjxx3CI95o7zbalGSJ7f57YFfAr4GXAQc3zY7HriwzV8ELEuyXZK96S6MX9m6uO5Ncmi7y+q4\ngTqSpDEYZctjMXBuu2NqK2BFVX0iyZeAFUlOAG4HXg5QVauSrABuBB4ETq6q9W1frwXOAbYHLmmT\nJGlMRpY8quo64BkzlH8HeP4G6iwHls9QvhI44NE1JEnj4BPmkqTeTB6SpN5MHpKk3kwekqTeTB6S\npN5MHpKk3kwekqTeTB6SpN5MHpKk3kwekqTeTB6SpN5MHpKk3kwekqTeTB6SpN5MHpKk3kwekqTe\nTB6SpN5MHpKk3kwekqTeTB6SpN5MHpKk3kwekqTeTB6SpN5MHpKk3kwekqTeTB6SpN5GljyS7Jnk\ns0luTLIqyetb+WlJ1iS5tk0vGqhzapLVSW5OcvhA+cFJrm/r3pkko4pbkjS3bUa47weBN1XVNUl2\nBK5Ocllb9/aq+qvBjZPsBywD9geeAnw6yb5VtR44E3g18GXgYuAI4JIRxi5JmsXIWh5Vtbaqrmnz\n9wE3AbvPUuUo4Pyqur+qbgVWA4ckWQzsVFVXVFUB5wFHjypuSdLc5uWaR5IlwDPoWg4Ar0tyXZKz\nk+zcynYH7hiodmcr273NTy+f6XNOTLIyycp169ZtxiOQJA0aefJIsgPwUeANVXUvXRfUU4GDgLXA\nX2+uz6qqs6pqaVUtXbRo0ebarSRpmpEmjyTb0iWOD1bVxwCq6q6qWl9VDwHvBQ5pm68B9hyovkcr\nW9Pmp5dLksZklHdbBXgfcFNVvW2gfPHAZi8BbmjzFwHLkmyXZG9gH+DKqloL3Jvk0LbP44ALRxW3\nJGluo7zb6lnAK4Hrk1zbyv4AODbJQUABtwEnAVTVqiQrgBvp7tQ6ud1pBfBa4Bxge7q7rLzTSpLG\naGTJo6q+AMz0PMbFs9RZDiyfoXwlcMDmi06StCl8wlyS1JvJQ5LUm8lDktSbyUOS1JvJQ5LUm8lD\nktSbyUOS1JvJQ5LUm8lDktSbyUOS1JvJQ5LUm8lDktSbyUOS1JvJQ5LUm8lDktSbyUOS1JvJQ5LU\nm8lDktSbyUOS1JvJQ5LUm8lDktSbyUOS1JvJQ5LUm8lDktSbyUOS1NvIkkeSPZN8NsmNSVYleX0r\n3yXJZUluaT93HqhzapLVSW5OcvhA+cFJrm/r3pkko4pbkjS3UbY8HgTeVFX7AYcCJyfZDzgFuLyq\n9gEub8u0dcuA/YEjgDOSbN32dSbwamCfNh0xwrglSXOYM3kk+W9JdmzzpyRZkeSguepV1dqquqbN\n3wfcBOwOHAWc2zY7Fzi6zR8FnF9V91fVrcBq4JAki4GdquqKqirgvIE6kqQxGKblcVpV3ZfkF4AX\nAR8E3tPnQ5IsAZ4BfBnYrarWtlXfBnZr87sDdwxUu7OV7d7mp5dLksZkmOSxvv18MfC/q+pCYLth\nPyDJDsBHgTdU1b2D61pLoobd1xCfdWKSlUlWrlu3bnPtVpI0zTDJY22SdwPHABcnedyQ9UiyLV3i\n+GBVfawV39W6omg/727la4A9B6rv0crWtPnp5Y9SVWdV1dKqWrpo0aJhQpQkbYRhksDLgX8Cjqyq\n7wG70i5yz6bdEfU+4KaqetvAqouA49v88cCFA+XLkmyXZG+6C+NXti6ue5Mc2vZ53EAdSdIYbLOh\nFUl2Gli8dKDsB8AXh9j3s4BXAtcnubaV/QFwOrAiyQnA7XTJiapalWQFcCPdnVonV9VUl9lrgXOA\n7YFL2iRJGpMNJg9gFd31iABPAe5r8zsA3+KRXUyPUlVfaNvP5PkbqLMcWD5D+UrggNk+T5I0fzbY\nbVVVe1bVXsAngZdU1ZOr6kl0t8l+Yr4ClCRNnmGueTyrqi6aWqiqj9N1SUmSFqjZuq2mrE1yCvD3\nbfkVwF2jC0mSNOmGaXn8Gt31jUuAi9v8saMMSpI02WZtebSxpX63qk6ep3gkSVuAWVse7VbZ585T\nLJKkLcQw1zyuTvIx4CPAD6cKBy+iS5IWlmGSx450SeNFA2VF90S4JGkBmjN5VNUr5yMQSdKWY5j3\neTwlyUeSrG3TBUmeMh/BSZIm0zC36r4f+EdgSZsua2WSpAVqmOSxW1W9t73h7/6q+jsefoGTJGkB\nGiZ5fDfJsjzsGOC7ow5MkjS5hkkev0n3Do1/BdbRDbP+m6MMSpI02Ya52+o2HnmbriRpgRvmbqv3\nJXnywPLOSd472rAkSZNsmG6rZ1bV96cW2qtoDx5dSJKkSTdM8tgqyZOmFpLsDGw7upAkSZNumOFJ\n3gF8KckFbfkY4C9GF5IkadINc8H8/UmuBp7XipZV1XWjDUuSNMmG6bYCeALw3ap6B7AmyV4jjEmS\nNOHmbHkk+SO6d5Y/DTgPeDzwIeDZow1NkjSphml5vJTuOY8fAlTVGmCnUQYlSZpswySP+6uq6N7h\nQZInjDYkSdKkGyZ5fCzJu4EnJfkNuhF2HVVXkhawYe62emuSFwI/Bg4EllfVJSOPTJI0sYa626qq\nLqmqN1bVG4BL28i6s0pydpK7k9wwUHZakjVJrm3TiwbWnZpkdZKbkxw+UH5wkuvbuncmSc9jlCRt\nZhtMHkl2SPJ7Sd6R5HltOPbXAN+gG2V3LucAR8xQ/vaqOqhNF7fP2g9YBuzf6pyRZOu2/ZnAq4F9\n2jTTPiVJ82i2lsff03VT3QKcDHwa+HXg5VV15Fw7rqp/Zvj3fhwFnN9eNnUrsBo4JMliYKequqJd\ntD8POHrIfUqSRmS2ax5Pq6qnAyR5D/BtYK+q+tEmfubrkhwHrATe1AZa3B24YmCbO1vZA21+erkk\naYxma3k8MDVTVeuBOzZD4jgTeCpwELAW+OtN3N8jJDkxycokK9etW7c5dy1JGjBb8jgwyXfb9D3g\nZ6fmk2zUa2ir6q6qWl9VDwHvBQ5pq9YAew5sukcrW9Pmp5dvaP9nVdXSqlq6aNGijQlRkjSE2ZLH\n44BFbdoV2G5gfqO+mds1jCkvAabuxLoIWJZkuyR7010Yv7Kq1gL3Jjm03WV1HHDhxny2JGnz2eA1\nj9ZVtdGSfBg4DNg1yZ3Am4HDkhxE97T6bcBJ7bNWJVkB3Ag8CJw88Pmvpbtza3vgkjZJksZomPd5\nbJSqOnaG4vfNsv1yYPkM5SuBAzZjaJKkTTTskOySJP0Hk4ckqbcNdlu1O6xqplVAVdUuI4tKkjTR\nZrvmseu8RSFJ2qIMfbdVkl3o3iI45VujCkqSNNnmvOaR5MgkX6cbGuTL7ednRh2YJGlyDXPBfDnd\nO8xvrqo9gcOBz480KknSRBsmeTxYVeuArZKkqi7j4WFFJEkL0DAPCd6TZAfgC8B5Se4GNnWAREnS\nFmyYlsfRdMniDcDn6AYmfPEIY5IkTbhhksepbSTcB6rqfVX1NuB3Rh2YJGlyDZM8Znrt65xvEpQk\nPXbN9oT5ScBrgH2TXDOwakfg6lEHJkmaXLNdMF8BXA78L+CUgfL7qurukUYlSZposz1h/j3ge8DL\nkuwPPKet+jxg8pCkBWyYJ8xPBj4C7NWmFUleO+rAJEmTa5jnPE4CDqmqHwAk+XPgX4AzRhmYJGly\nDXO3VYAfDyw/0MokSQvUbHdbbVNVDwIfAL6c5KNt1UuAc+cjOEnSZJqt2+pK4JlV9RdJPgc8u5W/\npqquGnlkkqSJNVvy+I+uqaq6ki6ZSJI0a/JYlGSDw5C0YUokSQvQbMlja2AHvDguSZpmtuSxtqr+\nZN4ikSRtMWa7VdcWhyRpRrMlj+fPWxSSpC3KBpNHVX13U3ac5Owkdye5YaBslySXJbml/dx5YN2p\nSVYnuTnJ4QPlBye5vq17ZxJbRJI0ZsM8Yb6xzuHR7wI5Bbi8qvahG7H3FIAk+wHLgP1bnTOSbN3q\nnAm8GtinTTO9X0SSNI9Gljyq6p+B6a2Xo3j46fRz6V5xO1V+flXdX1W3AquBQ5IsBnaqqiuqqoDz\nBupIksZkmIERN6fdqmptm/82sFub3x24YmC7O1vZA21+evmMkpwInAiw1157bXSQS0755EbXnTS3\nnd7vpY8L+djhsXP8G3PsUh+j7LaaVWtJ1Gbe51lVtbSqli5atGhz7lqSNGC+k8ddrSuK9nPqpVJr\ngD0Httujla1p89PLJUljNN/J4yLg+DZ/PHDhQPmyJNsl2ZvuwviVrYvr3iSHtrusjhuoI0kak5Fd\n80jyYeAwYNckdwJvBk6nexPhCcDtwMsBqmpVkhXAjcCDwMlVtb7t6rV0d25tD1zSJknSGI0seVTV\nsRtYNePDh1W1HFg+Q/lK4IDNGJokaRON7YK5JGnLZfKQJPVm8pAk9WbykCT1ZvKQJPVm8pAk9Wby\nkCT1ZvKQJPVm8pAk9WbykCT1ZvKQJPVm8pAk9TbfbxKUpInkWyT7seUhSerN5CFJ6s3kIUnqzeQh\nSerN5CFJ6s3kIUnqzeQhSerN5CFJ6s3kIUnqzeQhSerN5CFJ6s3kIUnqbSzJI8ltSa5Pcm2Sla1s\nlySXJbml/dx5YPtTk6xOcnOSw8cRsyTpYeNseTy3qg6qqqVt+RTg8qraB7i8LZNkP2AZsD9wBHBG\nkq3HEbAkqTNJ3VZHAee2+XOBowfKz6+q+6vqVmA1cMgY4pMkNeNKHgV8OsnVSU5sZbtV1do2/21g\ntza/O3DHQN07W5kkaUzG9TKoZ1fVmiQ/CVyW5GuDK6uqklTfnbZEdCLAXnvttXkilSQ9ylhaHlW1\npv28G/gHum6ou5IsBmg/726brwH2HKi+Ryubab9nVdXSqlq6aNGiUYUvSQvevCePJE9MsuPUPPAC\n4AbgIuD4ttnxwIVt/iJgWZLtkuwN7ANcOb9RS5IGjaPbajfgH5JMff6HqurSJFcBK5KcANwOvByg\nqlYlWQHcCDwInFxV68cQtySpmffkUVXfBA6cofw7wPM3UGc5sHzEoUmShjRJt+pKkrYQJg9JUm8m\nD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJvJg9J\nUm8mD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJvJg9JUm8mD0lSbyYPSVJv\nJg9JUm9bTPJIckSSm5OsTnLKuOORpIVsi0geSbYG3g28ENgPODbJfuONSpIWri0ieQCHAKur6ptV\n9WPgfOCoMcckSQvWlpI8dgfuGFi+s5VJksYgVTXuGOaU5KXAEVX139vyK4Gfr6rfnrbdicCJbfFn\ngJvnNdB+dgX+ddxBjNFCPv6FfOywsI9/Szj2n6qqRXNttM18RLIZrAH2HFjeo5U9QlWdBZw1X0Ft\niiQrq2rpuOMYl4V8/Av52GFhH/9j6di3lG6rq4B9kuyd5HHAMuCiMcckSQvWFtHyqKoHk/w28Clg\na+Dsqlo15rAkacHaIpIHQFVdDFw87jg2oy2ie22EFvLxL+Rjh4V9/I+ZY98iLphLkibLlnLNQ5I0\nQUwePSU5Okkl+c/jjmWSJPlB+7mk/fv82cC6XZM8kORdbfm0JGuSXJvkliQfGxwxIMnn2lA01ya5\nqd2CPbHS+UKSFw6UvSzJpUnWt+OYmk5p6z+XZOm0/RyW5J6B437zfB/LtHimYl+V5KtJ3pRkqxli\nvTbJp1v5ae33/9MD+3lDK5v4u4w28ph/pv0+p35vI+2aanF8YpSfMYwt5prHBDkW+EL7OdY/7gl2\nK3Ak8Edt+WXA9Bsc3l5VfwWQ5BjgM0meXlXr2vpXVNXKJLsA30hyThtdYOJUVSV5DfCRJJ+l+7v6\nc+AI4KtVdVCP3X2+ql6c5InAtUk+XlXXjCDsYfxoKvYkPwl8CNiJh//ff76qXjxDvevp7oicOoGY\n6fc/qyRbV9X6jYp602zMMb+T7v/zha3e0+cr2HGy5dFDkh2AZwMn0P1xTJ0F/FOSC5N8M8npSV6R\n5Mok1yd5Wtvul5N8OclXknw6yW6t/OKBM5l7khyf5PFJ3t/qfyXJc9u2r2pn6Ze2M/a/GNM/xVz+\nDbhp4EzzGGDFhjauqguAfwR+bYbVOwA/BMbxRTK0qroB+Djw+8AfA+dV1Tc2YX8/BK4GfnqubedD\nVd1N9wDubyfJHJv/X9rwQe3//z0MPBiX5AVJvpTkmiQfaX9XJLktyVuTXAO8LMnPJbmu/W38ZZIb\n2nZbt+Wr2vqTRnDIfY55Md2oF1P1rm9xLkny+Xac1yT5hVY+7HfGOUnek2Rlkq8neVSiTvLEJGe3\nul9JMm/DNpk8+jkKuLSqvg58J8nBrfxA4DXAfwFeCexbVYcAfwe8rm3zBeDQqnoG3dhc/xOgql7U\nznROAG6n+8M7uVtVT6dr4Zyb5PFtPwfRfRk/HTgmyeDDk5PkfGBZi2898K05tr8GGOwK/GCS6+hG\nCfjTMZ2F9vUWugT4QmAqsW+fR3ZbHTPMjpL8BHAoPc/YR6mqvkl3q/xPtqLnDBzXHw5sei9wR5ID\n6E6yLphakWRXuhbpL1bVM4GVwO8M1P1OVT2zqs4H3g+c1P4+Bn//JwD3VNXPAT8HvDrJ3pv1YJsh\nj/ntdC3nS5K8McmTW/ndwC+14zyGroUyZZjvDIAldGP7HQm8Z+B7YMofAp9pdZ8L/GVrtY6c3Vb9\nHAv8TZs/vy1/AriqqtYCJPkG3Vk0dM3357b5PYALkiwGHkfXtUOrsyvwAeDlVXVPkmcDfwtQVV9L\ncjuwb9v88qq6p9W7EfgpHjnu16S4FPhT4C4GvjxmMf3MbqrbahHwL0kurarbN3eQm1NV/TDJBcAP\nqur+Vvwf3SBDek6SrwAPAadP+PNMG+q2gnbyABwOPB/4jVZ+KN3I2F9sJ/OPA740UO8CgPYFvGNV\nTa37EDD1WS8AfjbdsEUATwL2YeBvaoQedcxV9f4kn6LrpjwKOCnJgcC2wLuSTCW/fQeqDfOdAbCi\nqh4CbknyTR55ggXdv8WvJPndtvx4YC/gpk08zjmZPIaUru/9ecDTkxTd2UgBnwTuH9j0oYHlh3j4\n3/hvgbdV1UVJDgNOa/vdmu4P7U9a18dcBj9rPRP6O6yqHye5GngT3ZfFr8xR5Rl0Z6HT97OudWP8\nPF3LbNI91KaNNdsX8lgleSrd/7m76c6YZ/MJ4C+BlVV170CvT4DLqurYDdT74TChAK+rqk8Nse0m\nGfaYq+pbwNnA2a177QDgl+lOng6k6+X594Eqw3xnQPcdwyzLAX61quZ9HD+7rYb3UuADVfVTVbWk\nqvakO9N5zpD1n8TD43EdP1B+OnBda6ZP+TzwCoAk+9KdSUzyII8b8tfA71fVd2fbKMmv0p1BfXiG\ndU+gSywbff1Am661AN8DvKuGeDisqv6N7vrP8mmrrgCelXY3Vuuz33eG+t8H7kvy861o2cDqTwG/\nlWTbto99R9FVM+wxp3tR3VQs/wn4Cbq/9ScBa1vL4ZV0J5x9vSzJVu06yFN59PfAp4DXTV2TSfKM\njfiMjTKRZ60T6ljgrdPKPgr8FsN9sZ1GdzfO94DPAFN9tL8LrEpybVv+Y+AM4Mwk1wMPAq+qqvvn\nvk45WVqXy4a6Xd6Y5NeBJwI3AM8buNMKumsePwK2A86pqqtHG+3IbD/wu4XumtnUmzA/meSBNv8l\nuheeTZKp2Lel+3/4AeBtw1aedkI0VbYuyauADyfZrhX/EfD1GXZxAvDeJA8B/0R34R266wJLgGva\nl+Y64Ohh45rDxhzzC4C/STLVsvi9qvp2kjOAjyY5jq4bd5hW1XT/D7iS7o6v11TVv0/7HvhT4B3A\ndeluKb6Vh7v3RsonzCVNpCQ7VNXU80OnAIur6vVjDmveJDkH+ERV/Z9xxzITWx6SJtWRSU6l+566\nHXjVeMPRIFsekqTevGAuSerN5CFJ6s3kIUnqzeShBS2zjKI6S50lSWYah2um7X40bXiSx22+6KXx\n8W4rLXRzjaI6kyV0Y1h9aIj9f2O24UmSbFNVDw4frjQZbHlIzfRRVLOBUVHpRgWYGiDvjbNsN6N0\n77z4QJIvAh/YUP0MP/rqoiQfTTfK7FVJntXK/+tAi+crSXYc2T+eFp6qcnJasBPdIIbTy74P7AY8\nAXh8K9uHbpwmgMPoHt6a2n5D2y0BfgRc26Z3t/LT6IZb336O+oe1WBbTPWm/BnhLW/d64B1t/kPA\ns9v8XsBNbf7jwLPa/A7ANuP+93Z67Ex2W0kbNtuoqMNut6Fuq4uq6kdD1B9m9NVfBPYbGLZip3Tv\nyPgi8LYkHwQ+VlV3Im0mJg9pwLRRVN/MhkdFHfTGIbcbNDjO0Wz1hxl9dSu6d8VM/9zTk3wSeBHd\nEOiHV9XXhohNmpPXPKRmhlFUNzQq6n3A4PWDTR09dVPr/yMDLxBqLRiSPK2qrq+qtwJX8eh3QUgb\nzeShhW7qTX+rgE/TfRG/pa07Azg+yVfpvninWgvXAevbrb1vnGW7YW1q/f8BLE33StYb6d5QB/CG\nJDekeyPjA8AlPfcrbZBjW0mSerPlIUnqzeQhSerN5CFJ6s3kIUnqzeQhSerN5CFJ6s3kIUnqzeQh\nSert/wObB3PyI6X4zgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73c039ec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test matplotlib Bar for the sum record of each dataframe\n",
    "x = np.arange(5)\n",
    "recordCount = [len(df1), len(df2), len(df3), len(MergeDF), len(SampleDF)]\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, recordCount)\n",
    "plt.xticks(x, ('Amazon', 'IMDB', 'YELP', 'DFMerge', 'DFSample'))\n",
    "plt.xlabel('DataFrames')\n",
    "plt.ylabel('Total Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MergeOne = MergeDF.query('Score == 1').count().Score\n",
    "MergeZero = MergeDF.query('Score == 0').count().Score\n",
    "SampleOne = SampleDF.query('Score == 1').count().Score\n",
    "SampleZero = SampleDF.query('Score == 0').count().Score\n",
    "\n",
    "MergeMeanZero = MergeDF.query('Score == 0').mean().Score\n",
    "MergeMeanOne = MergeDF.query('Score == 1').mean().Score\n",
    "SampleMeanZero = SampleDF.query('Score == 0').mean().Score\n",
    "SampleMeanOne = SampleDF.query('Score == 1').mean().Score\n",
    "\n",
    "MergeStdZero = MergeDF.query('Score == 0').std().Score\n",
    "MergeStdOne = MergeDF.query('Score == 1').std().Score\n",
    "SampleStdZero = SampleDF.query('Score == 0').std().Score\n",
    "SampleStdOne = SampleDF.query('Score == 1').std().Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEICAYAAACnL3iHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYFdWd//H3h01UcEHRHwENJMEFScSwaNxHjZhoXBIV\n1FEIRmVciDqawWUS4hIzxowZXKMTI44LoEnUmBhjSDBqRAKKIiCKgqERZHHFqCx+f3/UaSza3qrp\n27e7+bye5z636lSdU6fqLt97zqmqq4jAzMysiDblroCZmbU8Dh5mZlaYg4eZmRXm4GFmZoU5eJiZ\nWWEOHmZmVpiDhzV7kk6S9Mcm3uYCSYc05TbNWhIHj42IpBMlTZO0UtJiSQ9L2rfc9apLRNwVEYeW\nux711RICj6SQ9H56L6yQNEnSkAL5D5RUsQHbXCnp7eI1t+bCwWMjIel84GfAj4DtgR2BG4Ajy1mv\nukhqV+46tGK7R0QnYGfgduB6ST9oim2mx1bVreDXvIWICD9a+QPYElgJHFfLOpuQBZfX0+NnwCZp\n2YFABfA9YCmwGDga+DrwEvAmcHGurDHAfcAE4D3gGbIvjcrlo4FX0rLZwDG5ZcOBJ4FrgRXAFSnt\nibRcadlS4F1gJtA3t593AMuA14BLgTa5cp8ArgHeAuYDX6vleCwALkr1ewv4JdAxt/wIYAbwNvA3\n4Esp/f+Aj4EP0jH/HjAO+Pe0vDsQwFlp/vPp+LWprdy07DPAr9L+zQdGVTnmE9P+vwfMAgbUsn8B\nfKFK2rHAh8A2af7bwJxU3qvAGSl987R/H6d9XJnqNgh4KtV9MXA90KG2bVZ5f/0HsCQdw62Bh9K+\nvpWme+TyTE7vjb+l7f8W2Aa4K70v/g70zK2/C/BoOtZzgePL/bls6Y+yV8CPJniR4TBgDdCulnUu\nA6YA2wFd04fy8rTswJT/+0B74LT0ob4b6Azslr5MeqX1xwCr05dRe+CC9GXXPi0/Ln3ZtAGGAO8D\n3dKy4Wlb5wDtgE1ZP3gMBqYDW5EFkl1zee8AHkh16kkW2E7Nlbs61b0t8G9kQVI1HI8FwAvADkAX\nsoB2RVq2B1nw2jOVNSytv0ku7yG5skYAv03TJ5IFzgm5ZQ/UVW46VtPTa9AB+BzZF/rg3DH/kCyg\ntwWuAqbU8npXFzzap2P/tTR/OFlwE3AA8E/gy7n3REWV/P2BvdLr1pMs8Jxb2zarvL/+K+3rpmSB\n4FvAZun1vBe4P5dnMjAv1W9LsiD/EnBI2v4dwC/TupsDC8mCYbt0nJcDfcr92WzJj7JXwI8meJHh\nJGBJHeu8Anw9Nz8YWJCmDyQLDm3TfOf0RbBnbv3pwNFpekz+iyt98S0G9qth2zOAo9L0cOAfVZYP\n55PgcVD6ktiL9Gs9pbcFVuW/EIAzgMm5Mubllm2W9uH/1VCnBcDI3PzXgVfS9E2kwJpbPhc4IJc3\nHzw+T/bruQ1wc6pXRVo2Dji/rnLJAkrV43JR7gtyDPCn3LI+wAe1vN41fZEvAU6qIc/9wHdz74mK\nmspP65wL/KbKNt8la5m8DYzNlbWKXMuumrL6AW/l5icDl+Tmfwo8nJv/BjAjTQ8BHq9S3s+BHzTF\n56+1Pty3uHFYAWwrqV1ErKlhnc+QdfVUei2lrSsjItam6Q/S8xu55R8AnXLzCysnIuLjNLj6GQBJ\npwDnk/06JeXbtrq8VUXEnyVdTzZe81lJvyZr2WxK9su56j50z80vyZXzT0mV265Jvh754/FZYJik\nc3LLO7D+8crX+RVJ75N9Ae4HXA6cKmlnssAwth7lrgU+U2WQuS3weHX7R9ZK6FjHa74eSe3JWp1v\npvmvAT8AdiILfJuRdRPWlH8n4L+BAWnddmQ/KvK+HBHzqsm+LCI+zJW1GVn35GFkXVgAnSW1zb0P\nq77/ano/fhbYs8qxa0fWPWYN5AHzjcNTwEdk4xQ1eZ3sQ1Zpx5TWUDtUTkhqA/QAXpf0WeBW4Gyy\nvvWtyLqHlMtb662eI2JsRPQn+3W9E3AhWTfE6mr2YVFj7APrH4+FwJURsVXusVlE3FNL/R8j68br\nEBGL0vwwsi/GGfUodyEwv8qyzhHx9Q3Yv6qOIus+mippE7LxlWuA7dPr9Hs+eZ2q28ebgBeB3hGx\nBXAx67+utala3r+TDeTvmcraP6XXt7y8hcBjVY5dp4j4twaUZYmDx0YgIt4h6yu/QdLRkjaT1F7S\n1yRdnVa7B7hUUldJ26b179yAzfaX9M105sy5ZMFrCln/c5CNmSDp20Df+hYqaaCkPdOv5PfJ+vk/\nTr9GJwJXSuqcgtT5G7gPZ0nqIakLcAnZCQCQBb+RqR6StLmkwyV1TsvfIBuTyHuMLGD+Nc1PTvNP\n5H5J11buVOA9Sf8haVNJbSX1lTRwA/YPAEldJJ1E1pr7r4hYQdbi2YTsdVqTWiH506XfALaRtGUu\nrTNZt9RKSbuQjSs1VGey1sPb6fhvyFlgDwE7STo5ve/bp/fRrhtQ5kbPwWMjERE/JfsyvZTsC2Eh\n2ZfX/WmVK4BpwPNkXRPPpLSGeoCsr/kt4GTgmxGxOiJmk/VPP0X2BfRFssHo+tqC7Ev2LbKupBXA\nT9Kyc8gCyqtkZ1bdDdy2AftwN/DHVN4rpOMREdPIBt6vT/WYRzamUukqskD8tqQLUtpjZF+IlcHj\nCbKuncr5WstNAeYIsq6v+WQtrf8lGyxuqOckrUzb+Q5wXkR8P23vPWAUWUB+i2yg/8FcXV8k+8Hx\natrPz5B1H55IdnbWrXwSbBviZ2RdkcvJfnT8oaEFpX05FBhK1npcwieD89ZAiqi1h8CsMEljyAZj\n/7XcdTGz0nDLw8zMCitp8Ei3aZgpaYakaSmti6RHJb2cnrfOrX+RpHmS5koanEvvn8qZJ2ms0mky\nZmZWHiXttpK0gOwq1+W5tKuBNyPix5JGA1tHxH9I6kPWhzqI7NTEPwE7RcRaSVPJ+l+fJjvjY2xE\nPFyyipuZWa3K0W11FNmFUaTno3Pp4yPio4iYTzaIN0hSN2CLiJgSWaS7g9pPOTUzsxIr9UWCAfxJ\n0lrg5xFxC9k544vT8iVkN+mD7GKuKbm8FSltdZqumv4pkk4HTgfYfPPN+++yyy6NtR9mZhuF6dOn\nL4+IrnWtV+rgsW9ELJK0HfCopBfzCyMiJDVav1kKTrcADBgwIKZNm9ZYRZuZbRQkvVb3WiXutkpX\n0hIRS4HfkI1nvJG6okjPS9Pqi1j/it4eKW1Rmq6abmZmZVKy4JGuju1cOU12kc4LZBcaDUurDSO7\nmIyUPlTSJpJ6Ab2BqamL611Je6WzrE7J5TEzszIoZbfV9sBv0lm17YC7I+IPkv4OTJR0KtkVwscD\nRMQsSRPJbq28huz/Dipv23Am2Z/VbAo8nB5mZlYmrfYKc495mLVMq1evpqKigg8//LDula3BOnbs\nSI8ePWjfvv166ZKmR8SAuvL7luxm1qxUVFTQuXNnevbsia8HLo2IYMWKFVRUVNCrV68GleHbk5hZ\ns/Lhhx+yzTbbOHCUkCS22WabDWrdOXiYWbPjwFF6G3qMHTzMzKwwj3mYWbPWc/TvGrW8BT8+vM51\n/vCHP/Dd736XtWvX8p3vfIfRo0d/ap0xY8Zw9dVXs2DBArbbbjsAOnXqxMqVKxu1vpMnT6ZDhw7s\nvffeANx8881sttlmnHLKKY26naLc8jAzy1m7di1nnXUWDz/8MLNnz+aee+5h9uzZ1a677bbb8tOf\n/rSk9Zk8eTJ/+9vf1s2PHDmy7IEDHDzMzNYzdepUvvCFL/C5z32ODh06MHToUB54oPrrkkeMGMGE\nCRN48803P7XszjvvZNCgQfTr148zzjiDtWuzy9Z+8YtfsNNOOzFo0CBOO+00zj77bAB++9vfsuee\ne7LHHntwyCGH8MYbb7BgwQJuvvlmrr32Wvr168fjjz/OmDFjuOaaa3jxxRcZNGjQuu0tWLCAL37x\niwBMnz6dAw44gP79+zN48GAWL178qfptKAcPM7OcRYsWscMOn9wpqUePHixaVP0dkTp16sSIESP4\nn//5n/XS58yZw4QJE3jyySeZMWMGbdu25a677uL111/n8ssvZ8qUKTz55JO8+OInt/vbd999mTJl\nCs8++yxDhw7l6quvpmfPnowcOZLzzjuPGTNmsN9++61bf5dddmHVqlXMnz8fgAkTJjBkyBBWr17N\nOeecw3333cf06dMZMWIEl1xySWMeIsBjHmZmG2TUqFH069ePCy64YF3apEmTmD59OgMHDgTggw8+\nYLvttmPq1KkccMABdOnSBYDjjjuOl156CciubxkyZAiLFy9m1apV9br+4vjjj2fChAmMHj2aCRMm\nMGHCBObOncsLL7zAV7/6VSDrhuvWrVtj77aDh5lZXvfu3Vm4cOG6+YqKCrp3r/ZfIADYaqutOPHE\nE7nhhhvWpUUEw4YN46qrrlpv3fvvv7/Gcs455xzOP/98jjzySCZPnsyYMWPqrOuQIUM47rjj+OY3\nv4kkevfuzcyZM9ltt9146qmn6sy/IdxtZWaWM3DgQF5++WXmz5/PqlWrGD9+PEceeWStec4//3x+\n/vOfs2bNGgAOPvhg7rvvPpYuzW4a/uabb/Laa68xcOBAHnvsMd566y3WrFnDr371q3VlvPPOO+uC\n1Lhx49ald+7cmffee6/a7X7+85+nbdu2XH755QwZMgSAnXfemWXLlq0LHqtXr2bWrFkNPBo1c8vD\nzJq1+pxa25jatWvH9ddfz+DBg1m7di0jRoxgt912qzXPtttuyzHHHMO1114LQJ8+fbjiiis49NBD\n+fjjj2nfvj033HADe+21FxdffDGDBg2iS5cu7LLLLmy55ZZAdurvcccdx9Zbb81BBx20bizjG9/4\nBsceeywPPPAA11133ae2PWTIEC688MJ163fo0IH77ruPUaNG8c4777BmzRrOPffcOvehKN8Y0cya\nlTlz5rDrrruWuxols3LlSjp16sSaNWs45phjGDFiBMccc0xZ6lLdsa7vjRHdbWVm1oTGjBlDv379\n6Nu3L7169eLoo48ud5UaxN1WZmZN6Jprril3FRqFWx5mZlaYg4eZmRXm4GFmZoU5eJiZWWEeMDez\n5m3Mlo1c3jt1rjJixAgeeughtttuO1544YXqixkzhltvvZWuXbuyZs0afvSjH9V5MWFV06ZN4447\n7mDs2LHN9tbrNXHwMDOrYvjw4Zx99tl1fnGfd955XHDBBcyZM4f99tuPpUuX0qZN/Tt0BgwYwIAB\n2SUVkydPplOnTuuCx8iRIxu+A03A3VZmZlXsv//+625eWB+77ror7dq1Y/ny5SxYsICDDjqIL33p\nSxx88MH84x//AODee++lb9++7L777uy///5AFjCOOOKIZn3r9Zo4eJiZbaCnn36aNm3a0LVrV845\n5xyGDRvG888/z0knncSoUaMAuOyyy3jkkUd47rnnePDBB9fL35xvvV4TBw8zswaqbClccMEFTJgw\nAUk89dRTnHjiiQCcfPLJPPHEEwDss88+DB8+nFtvvXXdH0PVV+Wt1+GT4JG/9Xq/fv244oorqKio\naNwdrIXHPMzMGqhyzKM+br75Zp5++ml+97vf0b9/f6ZPn17v7ZTz1us1ccvDzKwR7b333owfPx6A\nu+66a10X1CuvvMKee+7JZZddRteuXdf7zxBovrder4lbHmbWvNXj1NrGdsIJJzB58mSWL19Ojx49\n+OEPf8ipp55ar7zXXXcd3/72t/nJT35C165d+eUvfwnAhRdeyMsvv0xEcPDBB7P77rvz2GOPrcvX\nXG+9XhPfkt3MmpXWfkv25sS3ZDczsybl4GFmZoU5eJhZs9Nau9Obkw09xg4eZtasdOzYkRUrVjiA\nlFBEsGLFCjp27NjgMny2lZk1Kz169KCiooJly5aVuyqtWseOHenRo0eD8zt4mFmz0r59e3r16lXu\nalgd3G1lZmaFlTx4SGor6VlJD6X5LpIelfRyet46t+5FkuZJmitpcC69v6SZadlYSSp1vc3MrGZN\n0fL4LjAnNz8amBQRvYFJaR5JfYChwG7AYcCNktqmPDcBpwG90+OwJqi3mZnVoKTBQ1IP4HDgf3PJ\nRwHj0vQ44Ohc+viI+Cgi5gPzgEGSugFbRMSUyE6/uCOXx8zMyqDULY+fAd8DPs6lbR8Rlf9YsgTY\nPk13B/J3CqtIad3TdNX0T5F0uqRpkqb5TA0zs9IpWfCQdASwNCJqvO9wakk02sncEXFLRAyIiAFd\nu3ZtrGLNzKyKUp6quw9wpKSvAx2BLSTdCbwhqVtELE5dUkvT+ouAHXL5e6S0RWm6arqZmZVJyVoe\nEXFRRPSIiJ5kA+F/joh/BR4EhqXVhgEPpOkHgaGSNpHUi2xgfGrq4npX0l7pLKtTcnnMzKwMynGR\n4I+BiZJOBV4DjgeIiFmSJgKzgTXAWRFR+V+NZwK3A5sCD6eHmZmVif/Pw8zM1vH/eZiZWck4eJiZ\nWWEOHmZmVpiDh5mZFebgYWZmhTl4mJlZYQ4eZmZWmIOHmZkV5uBhZmaFOXiYmVlhDh5mZlaYg4eZ\nmRXm4GFmZoU5eJiZWWEOHmZmVpiDh5mZFebgYWZmhTl4mJlZYQ4eZmZWmIOHmZkV5uBhZmaFOXiY\nmVlhDh5mZlaYg4eZmRXm4GFmZoU5eJiZWWEOHmZmVpiDh5mZFebgYWZmhTl4mJlZYQ4eZmZWmIOH\nmZkV5uBhZmaFOXiYmVlhJQsekjpKmirpOUmzJP0wpXeR9Kikl9Pz1rk8F0maJ2mupMG59P6SZqZl\nYyWpVPU2M7O6lbLl8RFwUETsDvQDDpO0FzAamBQRvYFJaR5JfYChwG7AYcCNktqmsm4CTgN6p8dh\nJay3mZnVoc7gIWmgpCmS3pH0oaSPJL1bV77IrEyz7dMjgKOAcSl9HHB0mj4KGB8RH0XEfGAeMEhS\nN2CLiJgSEQHckctjZmZlUJ+Wx43AMOBVoDNwNjC2PoVLaitpBrAUeDQinga2j4jFaZUlwPZpujuw\nMJe9IqV1T9NV06vb3umSpkmatmzZsvpU0czMGqBdPdZpExFzJbWLiNXArZKeBS6tK2NErAX6SdoK\n+I2kvlWWh6RoUM2r394twC0AAwYMaHi5Y7ZsrCpZazPmnXLXwKxZqE/weF9SB+A5ST8CFgNt68iz\nnoh4W9JfyMYq3pDULSIWpy6ppWm1RcAOuWw9UtqiNF013czMyqQ+3VbD03pnA2vJBqy/VVcmSV1T\niwNJmwJfBV4EHiTrBiM9P5CmHwSGStpEUq+0nampi+tdSXuls6xOyeUxM7MyqE/L4+sRcT3wIfCf\nAJLOBl6uI183YFw6Y6oNMDEiHpL0FDBR0qnAa8DxABExS9JEYDawBjgrdXsBnAncDmwKPJweZmZW\nJspOYKplBemZiPhylbRnI2KPktZsAw0YMCCmTZvWsMwe87CaeMzDWjlJ0yNiQF3r1djykDSE7LqL\nXpJ+nVu0BfD2hlfRzMxaqtq6raYCK8gGqG/Ipb8HPFvKSpmZWfNWY/BIF+rNB/7UdNUxM7OWoGRX\nmJuZWetV0ivMzcysdapP8GgTEXOBdhGxOiJuBQ4vcb3MzKwZa5IrzM3MrHVp6BXmx5awTmZm1szV\n2fKIiFcr/7ApIv6z9FUyM7PmrsaWhzKXSnoDWAD8Q9ISSRc3We3MzKxZqq3bahRwELBvRGwZEZ2B\n/YGDJI1qktqZmVmzVFvwGAYMiYh1N0CMiJeAE8nGQczMbCNVW/DYJCI+9Xd8EbEU6FC6KpmZWXNX\nW/D4qJZlqxq7ImZm1nLUdrbV7pLerCZdQKcS1cfMzFqA2oKHu6bMzKxatd1Vd21Ny8zMbONWnyvM\nzczM1uPgYWZmhTl4mJlZYbX9h/lbQFS3CIiI6FKyWpmZWbNW29lW2zZZLczMrEWp99lWkroAHXNJ\nr5eqUmZm1rzV5z/MD5f0ElABPJ2e/1zqipmZWfNVnwHzK4F9gLkRsQMwGHi8pLUyM7NmrT7BY026\nQWIbSYqIR4FBJa6XmZk1Y/X5D/N3JHUCngDukLQU+KC01TIzs+asPi2Po8mCxbnAZGARcEQJ62Rm\nZs1cfYLHRRGxNiJWR8QvIuK/gfNLXTEzM2u+6hM8Dqsm7fDGroiZmbUctV1hfgYwEthJ0jO5RZ2B\n6aWumJmZNV+1DZhPBCYBVwGjc+nvpb+iNTOzjVRtV5i/BbwFHCdpN2C/tOhxwMHDzGwjVp8rzM8C\n7gV2TI+Jks4sdcXMzKz5qs91HmcAgyJiJYCkHwF/A24sZcXMzKz5qs/ZVgJW5eZXp7TaM0k7SPqL\npNmSZkn6bkrvIulRSS+n561zeS6SNE/SXEmDc+n9Jc1My8ZKqnP7ZmZWOjUGD0mVrZL/A56WdKmk\nS8laHePqUfYa4N8jog+wF3CWpD5kg++TIqI32YD86LS9PsBQYDey04NvlNQ2lXUTcBrQOz2qO33Y\nzMyaSG0tj6kAEXE1WdfVP9NjZERcU1fBEbE4Ip5J0+8Bc4DuwFF8EnzGkV3BTkofHxEfRcR8YB4w\nSFI3YIuImBIRAdyRy2NmZmVQ25jHuq6hiJhKCiYNIaknsAfZLd23j4jFadESYPs03R2YkstWkdJW\np+mq6dVt53TgdIAdd9yxodU1M7M61BY8ukqq8TYk6TYldUo3VfwVcG5EvJsfroiIkFTdX902SETc\nAtwCMGDAgEYr18zM1ldb8GgLdKIeg+M1kdSeLHDcFRG/TslvSOoWEYtTl1TlNSOLgB1y2XuktEVp\numq6mZmVSW3BY3FEXNbQgtMZUb8A5lRppTwIDAN+nJ4fyKXfLem/gc+QDYxPjYi1kt6VtBdZt9cp\nwHUNrZeZmW24eo15NNA+wMnATEkzUtrFZEFjoqRTgdeA4wEiYpakicBssjO1zsr9j/qZwO3ApsDD\n6WFmZmVSW/A4eEMKjognqDkAVVt2RFxJ9re3VdOnAX03pD5mZtZ4ajxVNyLebMqKmJlZy1GfK8zN\nzMzW4+BhZmaFOXiYmVlhDh5mZlaYg4eZmRXm4GFmZoU5eJiZWWEOHmZmVpiDh5mZFebgYWZmhTl4\nmJlZYQ4eZmZWmIOHmZkV5uBhZmaFOXiYmVlhtf0Z1Ear54d3l7sK1kwtKHcFzJoJtzzMzKwwBw8z\nMyvMwcPMzApz8DAzs8IcPMzMrDAHDzMzK8zBw8zMCnPwMDOzwhw8zMysMAcPMzMrzMHDzMwKc/Aw\nM7PCHDzMzKwwBw8zMyvMwcPMzApz8DAzs8IcPMzMrLCSBQ9Jt0laKumFXFoXSY9Kejk9b51bdpGk\neZLmShqcS+8vaWZaNlaSSlVnMzOrn1K2PG4HDquSNhqYFBG9gUlpHkl9gKHAbinPjZLapjw3AacB\nvdOjaplmZtbEShY8IuKvwJtVko8CxqXpccDRufTxEfFRRMwH5gGDJHUDtoiIKRERwB25PGZmViZN\nPeaxfUQsTtNLgO3TdHdgYW69ipTWPU1XTa+WpNMlTZM0bdmyZY1XazMzW0/ZBsxTSyIaucxbImJA\nRAzo2rVrYxZtZmY5TR083khdUaTnpSl9EbBDbr0eKW1Rmq6abmZmZdTUweNBYFiaHgY8kEsfKmkT\nSb3IBsanpi6udyXtlc6yOiWXx8zMyqRdqQqWdA9wILCtpArgB8CPgYmSTgVeA44HiIhZkiYCs4E1\nwFkRsTYVdSbZmVubAg+nh5mZlVHJgkdEnFDDooNrWP9K4Mpq0qcBfRuxamZmtoF8hbmZmRXm4GFm\nZoU5eJiZWWEOHmZmVpiDh5mZFVays63MrITGbFnuGlhzNeadJtmMWx5mZlaYg4eZmRXm4GFmZoU5\neJiZWWEOHmZmVpiDh5mZFebgYWZmhTl4mJlZYQ4eZmZWmIOHmZkV5uBhZmaFOXiYmVlhDh5mZlaY\ng4eZmRXm4GFmZoU5eJiZWWH+MyizFqjnh3eXuwrWTC1oou245WFmZoU5eJiZWWEOHmZmVpiDh5mZ\nFebgYWZmhTl4mJlZYQ4eZmZWmIOHmZkV5uBhZmaFOXiYmVlhDh5mZlaYg4eZmRXWYoKHpMMkzZU0\nT9LoctfHzGxj1iKCh6S2wA3A14A+wAmS+pS3VmZmG68WETyAQcC8iHg1IlYB44GjylwnM7ONVkv5\nP4/uwMLcfAWwZ9WVJJ0OnJ5mV0qa2wR12xhsCywvdyWaA/1XuWtgNfB7NGmE9+hn67NSSwke9RIR\ntwC3lLserY2kaRExoNz1MKuJ36NNr6V0Wy0CdsjN90hpZmZWBi0lePwd6C2pl6QOwFDgwTLXycxs\no9Uiuq0iYo2ks4FHgLbAbRExq8zV2pi4K9CaO79Hm5giotx1MDOzFqaldFuZmVkz4uBhZmaFOXi0\nIpJC0p25+XaSlkl6qAm2fbuk+ZKek/SSpDsk9cgtXyBppqQZ6bF3qetkpSfpEkmzJD2fXtdPXX/V\niNuaLKnW03HTOv+QpFza/ZJWlqpeG6sWMWBu9fY+0FfSphHxAfBVCp7SLKldRKxp4PYvjIj70gf3\nXODPkvqmuwIA/EtE+EKuVkLSV4AjgC9HxEeStgU6lLlaAG8D+wBPSNoK6Fbm+rRKbnm0Pr8HDk/T\nJwD3VC6QtLmk2yRNlfSspKNS+nBJD0r6MzBJUhtJN0p6UdKjkn4v6di0bn9Jj0maLukRSZ/6YEbm\nWmAJ2f3IrHXqBiyPiI8AImJ5RLwu6fuS/i7pBUm3VLYCUqvgWknTJM2RNFDSryW9LOmKtE7P9L67\nK61zn6TNqm5Y0qGSnpL0jKR7JXXKLR5Pdjo/wDeBX1fJe2Gq3/OSfphLvz+9r2elu1VUpq+UdGVq\nVU+RtH1KPy7t43OS/tooR7QFcfBofcYDQyV1BL4EPJ1bdgnw54gYBPwL8BNJm6dlXwaOjYgDyD5w\nPcluQnky8BUASe2B69J6/YHbgCtrqcszwC65+b+kro2na8pgLcofgR1SN+WNkg5I6ddHxMCI6Ats\nStY6qbQqXQl+M/AAcBbQFxguaZu0zs7AjRGxK/AucGZ+o6mFcylwSER8GZgGnJ9bZRKwf7qh6lBg\nQi7voUApTy1ZAAADB0lEQVRvsvvl9QP6S9o/LR6R3tcDgFG5+mwOTImI3YG/Aqel9O8Dg1P6kfU/\nbK2Du61amYh4XlJPslbH76ssPhQ4UtIFab4jsGOafjQi3kzT+wL3RsTHwBJJf0npO5N90B9NPybb\nAotrqY6qzLvbqhWJiJWS+gP7kf0YmaDs7xLek/Q9YDOgCzAL+G3KVnlx70xgVkQsBpD0KtldJN4G\nFkbEk2m9O4FRwDW5Te9F9sPmyfQ+7AA8lVu+FniCLHBsGhELckMgh6bHs2m+E1kw+StZwDgmpe+Q\n0lcAq4DKccPpZN3BAE8Ct0uaSJXWzcbAwaN1epDsw3YgsE0uXcC3ImK9G0amQc7361GuyD7wX6ln\nPfYg+xVorVRErAUmA5MlzQTOIGvxDoiIhZLGkP1IqfRRev44N105X/l9VPXis6rzIvuxc0ItVRsP\n/AYYU03eqyLi5+slSgcChwBfiYh/Spqcq/fq+OSCuLWV9YyIkemzczgwXVL/iFhRS51aFXdbtU63\nAT+MiJlV0h8Bzsn1Qe9RQ/4ngW+lsY/tyYIQwFygaxooRVJ7SbtVzazMKLI+8T9s8N5YsyRpZ0m9\nc0n9yN4jAMvTOMSxDSh6x8r3GHAiWSsibwqwj6QvpHpsLmmnKus8DlxFbswveQQYUTlGIqm7pO2A\nLYG3UuDYhax1UytJn4+IpyPi+8Ay1r//XqvnlkcrFBEVwNhqFl0O/Ax4XlIbYD7r90dX+hVwMDCb\n7Fb4zwDvRMSqNHA+VtKWZO+fn5F1S0A2hvKfZN0VU8i6qVZ9qnRrLToB16UzmtYA88j+EuFt4AWy\nEyb+3oBy5wJnSbqN7D14U35hRCyTNBy4R9ImKflS4KXcOsH6XV2V6X+UtCvwVPoNtRL4V7IfOSMl\nzUnbn1KPev4kBU+RtbCfK7KTLZ1vT2LVktQp9WlvA0wF9omIJeWul7VuabzuoTTYbs2YWx5Wk4fS\nL8oOwOUOHGaW55aHmZkV5gFzMzMrzMHDzMwKc/AwM7PCHDzMzKwwBw8zMyvs/wN6EDm5oT+npgAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73bf1d9780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2\n",
    "ZeroSum = (MergeZero, SampleZero)\n",
    "OneSum = (MergeOne, SampleOne)\n",
    "ZeroStd = (MergeStdZero, SampleStdZero)\n",
    "OneStd = (MergeStdOne, SampleStdOne)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.8    # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, ZeroSum, width, yerr=ZeroStd)\n",
    "p2 = plt.bar(ind, OneSum, width, bottom=ZeroSum, yerr=OneStd)\n",
    "\n",
    "plt.ylabel('Total Data')\n",
    "plt.title('Comparison between DataFrame')\n",
    "plt.xticks(ind, ('MergeDF', 'SampleMeans'))\n",
    "plt.yticks(np.arange(0, 5001, 1000))\n",
    "plt.legend((p1[0], p2[0]), ('0 Negative', '1 Positive'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the ratio of Positive & Negative Sentence still the same after sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Creation\n",
    "#### Here at this step we are trying to add more feature to our dataframe by adding tokenized sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original function from news_data_mining.ipynb\n",
    "def tokenize_text(text, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Tokenize text using the nltk library\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for d in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(d, language='english'):\n",
    "            # filters here\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this to fix Resource 'tokenizers/punkt/PY3/english.pickle' not found.\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# takes a like a minute or two to process\n",
    "SampleDF['unigrams'] = SampleDF['Sentence'].apply(lambda x: tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614    [the, worst, phone, from, samsung, ..., crap, ...\n",
       "265                   [Battery, life, is, real, good, .]\n",
       "330    [The, servers, are, not, pleasant, to, deal, w...\n",
       "422    [Oh, and, I, forgot, to, also, mention, the, w...\n",
       "Name: unigrams, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the result of our new created feature called unigrams\n",
    "SampleDF[0:4][\"unigrams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>the worst phone from samsung...crap..... this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[the, worst, phone, from, samsung, ..., crap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Battery life is real good.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Battery, life, is, real, good, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>The servers are not pleasant to deal with and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[The, servers, are, not, pleasant, to, deal, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Oh, and, I, forgot, to, also, mention, the, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Score datasource  \\\n",
       "614  the worst phone from samsung...crap..... this ...      0     amazon   \n",
       "265                         Battery life is real good.      1     amazon   \n",
       "330  The servers are not pleasant to deal with and ...      0       yelp   \n",
       "422  Oh and I forgot to also mention the weird colo...      0     amazon   \n",
       "\n",
       "                                              unigrams  \n",
       "614  [the, worst, phone, from, samsung, ..., crap, ...  \n",
       "265                 [Battery, life, is, real, good, .]  \n",
       "330  [The, servers, are, not, pleasant, to, deal, w...  \n",
       "422  [Oh, and, I, forgot, to, also, mention, the, w...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The current Dataframe Header\n",
    "SampleDF[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the sentence into a term-document matrix (using default CountVectorizer() function)\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(SampleDF.Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'product', 'good', 'seller']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing the result\n",
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\" \".join(list(SampleDF[4:5].Sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good product, good seller.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining all the token back together for previewing\n",
    "\" \".join(list(SampleDF[4:5].Sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 2280)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check the shape of this matrix by:\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '100', '11', '13', '17', '18', '1948', '1949', '1979', '1980']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain the feature names of the vectorizer, i.e., the terms\n",
    "count_vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>the worst phone from samsung...crap..... this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[the, worst, phone, from, samsung, ..., crap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Battery life is real good.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Battery, life, is, real, good, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>The servers are not pleasant to deal with and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[The, servers, are, not, pleasant, to, deal, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Oh, and, I, forgot, to, also, mention, the, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Good product, good seller.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Good, product, ,, good, seller, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Score datasource  \\\n",
       "614  the worst phone from samsung...crap..... this ...      0     amazon   \n",
       "265                         Battery life is real good.      1     amazon   \n",
       "330  The servers are not pleasant to deal with and ...      0       yelp   \n",
       "422  Oh and I forgot to also mention the weird colo...      0     amazon   \n",
       "280                         Good product, good seller.      1     amazon   \n",
       "\n",
       "                                              unigrams  \n",
       "614  [the, worst, phone, from, samsung, ..., crap, ...  \n",
       "265                 [Battery, life, is, real, good, .]  \n",
       "330  [The, servers, are, not, pleasant, to, deal, w...  \n",
       "422  [Oh, and, I, forgot, to, also, mention, the, w...  \n",
       "280                [Good, product, ,, good, seller, .]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What the dataframe looks like so far\n",
    "SampleDF[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the matrix (its so sparse with 0 data)\n",
    "X_counts[0:5,0:100].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing out the function\n",
    "VectorA = count_vect.transform(['Something completely new.']).toarray()\n",
    "VectorB = count_vect.transform(['00 Something completely new. ']).toarray()\n",
    "\n",
    "# Comparing if two vector are same or not\n",
    "(VectorA==VectorB).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not sure why the result above is True, it supposedly to be False <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to visualize the term using plot heat map\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term_10',\n",
       " 'term_100',\n",
       " 'term_11',\n",
       " 'term_13',\n",
       " 'term_17',\n",
       " 'term_18',\n",
       " 'term_1948',\n",
       " 'term_1949',\n",
       " 'term_1979',\n",
       " 'term_1980',\n",
       " 'term_1995',\n",
       " 'term_20',\n",
       " 'term_2006',\n",
       " 'term_20th',\n",
       " 'term_23',\n",
       " 'term_30',\n",
       " 'term_375',\n",
       " 'term_40',\n",
       " 'term_45',\n",
       " 'term_50']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_y = [\"doc_\"+ str(i) for i in list(SampleDF.index)[0:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_z = X_counts[0:20, 0:20].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original function from news_data_mining.ipynb\n",
    "def plot_heat_map(plot_x, plot_y, plot_z):\n",
    "    \"\"\" Helper to plot heat map \"\"\"\n",
    "    trace = {\n",
    "        \"x\": plot_x,\n",
    "        \"y\": plot_y,\n",
    "        \"z\": plot_z,\n",
    "        \"colorscale\": [[0.0, \"rgb(158,1,66)\"], [0.1, \"rgb(213,62,79)\"], [0.2, \"rgb(244,109,67)\"], [0.3, \"rgb(253,174,97)\"], [0.4, \"rgb(254,224,139)\"], [0.5, \"rgb(255,255,191)\"], [0.6, \"rgb(230,245,152)\"], [0.7, \"rgb(171,221,164)\"], [0.8, \"rgb(102,194,165)\"], [0.9, \"rgb(50,136,189)\"], [1.0, \"rgb(94,79,162)\"]],\n",
    "        \"type\": \"heatmap\"\n",
    "    }\n",
    "\n",
    "    data = go.Data([trace])\n",
    "    layout = {\n",
    "        \"legend\": {\n",
    "            \"bgcolor\": \"#F5F6F9\",\n",
    "            \"font\": {\"color\": \"#4D5663\"}\n",
    "        },\n",
    "        \"paper_bgcolor\": \"#F5F6F9\",\n",
    "        \"plot_bgcolor\": \"#F5F6F9\",\n",
    "        \"xaxis1\": {\n",
    "            \"gridcolor\": \"#E1E5ED\",\n",
    "            \"tickfont\": {\"color\": \"#4D5663\"},\n",
    "            \"title\": \"\",\n",
    "            \"titlefont\": {\"color\": \"#4D5663\"},\n",
    "            \"zerolinecolor\": \"#E1E5ED\"\n",
    "        },\n",
    "        \"yaxis1\": {\n",
    "            \"gridcolor\": \"#E1E5ED\",\n",
    "            \"tickfont\": {\"color\": \"#4D5663\"},\n",
    "            \"title\": \"\",\n",
    "            \"titlefont\": {\"color\": \"#4D5663\"},\n",
    "            \"zeroline\": False,\n",
    "            \"zerolinecolor\": \"#E1E5ED\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(data = data, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/86.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw the plot\n",
    "py.iplot(plot_heat_map(plot_x, plot_y, plot_z), filename='plotly-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 3: From the chart above, we can see how sparse the term-document matrix is; i.e., there is only one terms with frequency of 1 in the subselection of the matrix. By the way, you may have noticed that we only selected 20 articles and 20 terms to plot the histrogram. As an excersise you can try to modify the code above to plot the entire term-document matrix or just a sample of it.\n",
    "\n",
    "The great thing about what we have done so far is that we now open doors to new problems. Let us be optimistic. Even though we have the problem of sparsity and a very high dimensional data, we are now closer to uncovering wonders from the data. You see, the price you pay for the hard work is worth it because now you are gaining a lot of knowledge from what was just a list of what appeared to be irrelevant articles. Just the fact that you can blow up the data and find out interesting characteristics about the dataset in just a couple lines of code, is something that truly inspires me to practise Data Science. That's the motivation right there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for all clients.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/72.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whole SampleDF\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0::]]\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(SampleDF.index)[0::]]\n",
    "plot_z = X_counts[0::, 0::].toarray()\n",
    "\n",
    "py.iplot(plot_heat_map(plot_x, plot_y, plot_z), filename='plotly-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Dimensionality Reduction\n",
    "#### Score value is already in 1 dimentional, no need to do the dimesionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = PCA(n_components=3).fit_transform(X_counts.toarray())\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original function from news_data_mining.ipynb\n",
    "def get_trace(X_pca, data, category, color):\n",
    "    \"\"\" Build trace for plotly chart based on category \"\"\"\n",
    "    trace = go.Scatter3d(\n",
    "        x=X_pca[data.apply(lambda x: True if x==category else False), 0],\n",
    "        y=X_pca[data.apply(lambda x: True if x==category else False),1],\n",
    "        z=X_pca[data.apply(lambda x: True if x==category else False),2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            line=dict(\n",
    "                color=color,\n",
    "                width=0.2\n",
    "            ),\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=data[data.apply(lambda x: True if x==category else False).tolist()]\n",
    "    )\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/78.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = get_trace(X_reduced, SampleDF[\"datasource\"], \"amazon\", \"rgb(71,233,163)\")\n",
    "trace2 = get_trace(X_reduced, SampleDF[\"datasource\"], \"imdb\", \"rgb(52,133,252)\")\n",
    "trace3 = get_trace(X_reduced, SampleDF[\"datasource\"], \"yelp\", \"rgb(229,65,136)\")\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plotly-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Atrribute Transformation / Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_frequencies = []\n",
    "for j in range(0,X_counts.shape[1]):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_word_frequency(word_list, plot_title):\n",
    "    trace1 = {\n",
    "        \"x\": list(word_list[0]),\n",
    "        \"y\": list(word_list[1]),\n",
    "        \"type\": \"bar\"\n",
    "    }\n",
    "\n",
    "    data = go.Data([trace1])\n",
    "\n",
    "    layout = {\n",
    "        \"title\": plot_title,\n",
    "        \"yaxis\": {\"title\": \"Frequency\"}\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(data = data, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/80.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(plot_word_frequency([count_vect.get_feature_names(), term_frequencies], \"Term Frequency Distribution\"), filename='plotly-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: The chart above contains all the vocabulary, and it's computationally intensive to both compute and visualize. You can try to reduce the number of terms you want to visualize as an exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term frequency in range of 0~100\n",
    "term_frequencies = []\n",
    "for j in range(0,100):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))\n",
    "    \n",
    "py.iplot(plot_word_frequency([count_vect.get_feature_names(), term_frequencies], \"Term Frequency Distribution\"), filename='plotly-5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Additionally, you can attempt to sort the terms on the x-axis by frequency instead of in alphabetical order.\n",
    "Since we have those term frequencies, we can also transform the values in that vector into the log distribution. All we need is to import the math library provided by python and apply it to the array of values of the term frequency vector. This is a typical example of attribute transformation. Let's go for it. The log distribution is a technique to visualize the term frequency into a scale that makes you easily visualize the distribution in a more readable format. In other words, the discrepancies between the term frequencies are now better observable. Let us try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~DataMiningNTHU/84.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_word_frequency2(word_list, plot_title):\n",
    "    trace1 = {\n",
    "        \"x\": list(word_list[0]),\n",
    "        \"y\": list(word_list[1]),\n",
    "        \"type\": \"bar\",\n",
    "        \"orientation\" : 'h'\n",
    "    }\n",
    "\n",
    "    data = go.Data([trace1])\n",
    "\n",
    "    layout = {\n",
    "        \"title\": plot_title,\n",
    "        \"xaxis\": {\"title\": \"Frequency\"}\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(data = data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "# Term frequency in range of 0~100\n",
    "term_frequencies = []\n",
    "for j in range(0,100):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))\n",
    "\n",
    "sortedFrequency = np.sort(term_frequencies, axis=None)\n",
    "sortedFeatureName = np.sort(count_vect.get_feature_names(), axis=None)\n",
    "py.iplot(plot_word_frequency2([sortedFrequency, sortedFeatureName], \"Term Frequency Distribution\"), filename='plotly-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing with 10 frequencies\n",
    "term_frequencies = []\n",
    "for j in range(0,10):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))\n",
    "\n",
    "# Normalize the frequencies\n",
    "normalized = ( sortedFrequency-np.mean(sortedFrequency) ) / np.std(sortedFrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculte Mean and Std\n",
    "mu, sigma = np.mean(normalized), np.std(normalized)\n",
    "s = np.random.lognormal(mu, sigma, 1000)\n",
    "\n",
    "count, bins, ignored = plt.hist(s, 100, normed=True, align='mid')\n",
    "x = np.linspace(min(bins), max(bins), 10000)\n",
    "\n",
    "pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))/ (x * sigma * np.sqrt(2 * np.pi)))\n",
    "\n",
    "plt.plot(x, pdf, linewidth=2, color='r')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "# Enable xtics text [Still Bugged]\n",
    "plt.xticks((term_frequencies), (count_vect.get_feature_names()), rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Discretization and Binarization\n",
    "#### Since the \"Score\" column of the data is already discrete value also in form of Binary, 0 for Negative and 1 for Positive, we dont need to do this part, so for this demonstration we use the sourcedata instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = preprocessing.LabelBinarizer()\n",
    "mlb.fit(SampleDF.datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amazon', 'imdb', 'yelp'], \n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SampleDF['Bin_Category'] = mlb.transform(SampleDF['datasource']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>datasource</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>Bin_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>the worst phone from samsung...crap..... this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[the, worst, phone, from, samsung, ..., crap, ...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Battery life is real good.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Battery, life, is, real, good, .]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>The servers are not pleasant to deal with and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[The, servers, are, not, pleasant, to, deal, w...</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Oh, and, I, forgot, to, also, mention, the, w...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Good product, good seller.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>[Good, product, ,, good, seller, .]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Score datasource  \\\n",
       "614  the worst phone from samsung...crap..... this ...      0     amazon   \n",
       "265                         Battery life is real good.      1     amazon   \n",
       "330  The servers are not pleasant to deal with and ...      0       yelp   \n",
       "422  Oh and I forgot to also mention the weird colo...      0     amazon   \n",
       "280                         Good product, good seller.      1     amazon   \n",
       "\n",
       "                                              unigrams Bin_Category  \n",
       "614  [the, worst, phone, from, samsung, ..., crap, ...    [1, 0, 0]  \n",
       "265                 [Battery, life, is, real, good, .]    [1, 0, 0]  \n",
       "330  [The, servers, are, not, pleasant, to, deal, w...    [0, 0, 1]  \n",
       "422  [Oh, and, I, forgot, to, also, mention, the, w...    [1, 0, 0]  \n",
       "280                [Good, product, ,, good, seller, .]    [1, 0, 0]  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleDF[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# Finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM-HW1",
   "language": "python",
   "name": "datamininghw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
